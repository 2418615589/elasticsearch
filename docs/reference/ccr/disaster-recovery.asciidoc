[role="xpack"]
[[ccr-disaster-recovery-tutorial]]
=== Tutorial: Disaster Recovery {ccr}
++++
<titleabbrev>Disaster Recovery {ccr}</titleabbrev>
++++

////
[source,console]
----
PUT /server-metrics
{
  "settings" : {
    "index" : {
      "number_of_shards" : 1,
      "number_of_replicas" : 0
    }
  },
  "mappings" : {
    "properties" : {
      "@timestamp" : {
        "type" : "date"
      },
      "accept" : {
        "type" : "long"
      },
      "deny" : {
        "type" : "long"
      },
      "host" : {
        "type" : "keyword"
      },
      "response" : {
        "type" : "float"
      },
      "service" : {
        "type" : "keyword"
      },
      "total" : {
        "type" : "long"
      }
    }
  }
}
----
// TESTSETUP
////
Using this guide to failover production (leader) to a disaster recovery
(follower) site.  Once the production site came back, turn the production site
to be the disaster recovery site with the follower role. 
This tutorial requires users to setup uni-directional {ccr} CCR between two
clusters following the setup from {ref}/getting-started.html first. 

==== Limitation
{ccr} CCR provides functionality to replicate indices generated by users only.
It is not designed, and should not be used for replicating system-generated
indices. It is also not designed for replicating cluster or snapshot settings
and cannot replicate ilm or slm policies across the clusters. 

==== Prerequisites
To complete this tutorial, you need:

* The `manage` cluster privilege on the local cluster.
* A license on both clusters that includes {ccr}. {kibana-ref}/managing-licenses.html[Activate a free 30-day trial].
* An index on the remote cluster that contains the data you want to replicate.
* In the local cluster, all nodes with the `master` <<node-roles,node role>> must
also have the <<remote-node,`remote_cluster_client`>> role. The local cluster
must also have at least one node with both a data role and the
<<remote-node,`remote_cluster_client`>> role. Individual tasks for coordinating
replication scale based on the number of data nodes with the
`remote_cluster_client` role in the local cluster.
* Follow {ref}/getting-started.html to have two clusters connected
 bi-directional remotely and have some indices setup with uni-directional
 {ccr} CCR already.

TIP: Ingestion or updates should only be written to the leader cluster, all
search queries can be directed to either leader or follower clusters.

Assuming the two clusters setup are `prod1` and `prod2` while `prod1` being the
leader and `prod2` being the follower. The index replicated from `prod1` to
`prod2` is called `my_index`.

==== When `prod1` is down

Step1: On the Clients side, pause ingestion of `my_index` into `prod1`.

TIP: Ensure no writes are occurring on the leader index (if the data centre is
down, or cluster is unavailable, no action needed).

Step2: On the Elasticsearch side, convert the follower indices in the `prod2`
into regular indices so that it will be capable of accepting writes.
[source,console-result]
----
### On prod2 cluster ###
POST /my_index/_ccr/pause_follow
POST /my_index/_close           
POST /my_index/_ccr/unfollow    
POST /my_index/_open
----

Step3: On the Client side, manually re-enable ingestion of `my_index` and
direct to the `prod2` cluster. (You can test that the index should be writable:
[source,console-result]
----
### On prod2 cluster ###
POST my_index/_doc/2
{
  "foo": "new"
}  
----
TIP: You should also redirect all search traffic to the `prod2` cluster during
this time.


==== When `prod1` comes back
You can simply swap the leader and follower role of `prod1` and `prod2` so that
`prod2` becomes the new leader and `prod1` becomes the follower. 

Step1: In order for the indices to follow the leader cluster, existing data
need to be discard before you can turn the index into a follower. Ensure the
most up-to-date data is available on `prod2` prior to deleting the index on
`prod1`.  

Step2: Create follower indices in `prod1`, to follow the leader index in
`prod2`.  


[source,console-result]
----
### On prod1 cluster ###
DELETE my_index

### On prod1 cluster ###
PUT /my_index/_ccr/follow 
{ 
  "remote_cluster" : "prod2", 
  "leader_index" : "my_index" 
}
----

NOTE: It might take some time for the follower indices on `prod1` to be
recreated and replicated from `prod2`.

